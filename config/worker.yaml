# ~~~ Configurations for the NES Worker ~~~

# ~~ IPs and Ports ~~
# Set worker IP
localWorkerIp: 127.0.0.1

# Set IP address of NES Coordinator to which the NES Worker should connect
coordinatorIp: 127.0.0.1

# Set RPC Server port of NES Coordinator to which the NES Worker should connect
# Needs to be the same as rpcPort in Coordinator
coordinatorPort: 4000

# Set RPC server port of NES Worker
rpcPort: 3000

# Set the data port of the NES Worker
dataPort: 3001

# Set number of computing slots in NES Worker
numberOfSlots: 65535

# Set the number of worker threads
numWorkerThreads: 1

# Number buffers in global buffer pool
numberOfBuffersInGlobalBufferManager: 1024

# Number buffers in task local buffer pool
numberOfBuffersPerWorker: 128

# Number buffers in source local buffer pool
numberOfBuffersInSourceLocalBufferPool: 64

# Size of buffer to pass data through the system
bufferSizeInBytes: 4096

# Set parentId of NES Worker node
parentId: -1

# The log level (LOG_NONE, LOG_WARNING, LOG_DEBUG, LOG_INFO, LOG_TRACE)
logLevel: LOG_DEBUG

# ~~~ Physical Stream Configurations ~~~

# A Physical Stream may be associated with multiple Instances of a logicalStreamName, a physicalStreamName and a SourceType
# If no Physical Stream Config is given, the worker will be created without a physical stream
# Available source Types: DefaultSource, CSVSource, MQTTSource, SenseSource, OPCSource (ToDo: Make source available),
#                         ZMQSource (ToDo: Make source available), KafkaSource (ToDo: Make source available),
#                         BinarySource (ToDo: Make source available))
physicalStreamConfigs:
  # Set logical stream name where this stream is added to
  - logicalStreamName: default_stream_log
    # Set physical stream name
    physicalStreamName: default_stream_phy
    # CSVSource and its needed configuration params
    CSVSourceType:
      # Set file path
      - filePath: /tests/test_data/exdra.csv
        # Skip first line of the file
        skipHeader: false
        # Set delimiter, e.g. , or .
        delimiter: ","
        # Set number of buffers to produce, i.e. how often the read csv file is repeated
        numberOfBuffersToProduce: 1
        # Set number of tuples to produce per buffer
        numberOfTuplesToProducePerBuffer: 1
        # Set sampling frequency of source
        sourceFrequency: 1
        # Set input data format
        inputFormat: JSON
  # Set logical stream name where this stream is added to
  - logicalStreamName:
  # Set physical stream name
    physicalStreamName:
    # DefaultSource: A simple source with default data created inside NES, useful for testing
    DefaultSourceType:
      # Set number of buffers to produce, i.e. how often the default data is repeated for this source
      - numberOfBuffersToProduce: 1
  # Set logical stream name where this stream is added to
  - logicalStreamName:
    # Set physical stream name
    physicalStreamName:
    # SenseSource: Creates a Sense source
    SenseSourceType:
    # Set user defined function
      - udfs:
  # Set logical stream name where this stream is added to
  - logicalStreamName:
    # Set physical stream name
    physicalStreamName:
    # BinarySource: read from a binary source file
    BinarySourceType:
      # Set file path
      - filePath:
  # Set logical stream name where this stream is added to
  - logicalStreamName:
    # Set physical stream name
    physicalStreamName:
    # MQTTSource: Connect to an MQTT broker and read data from there
    MQTTSourceType:
      # Set url to connect to
      - url:
      # Set clientId
        clientId:
      # Set userName
        userName:
      # Set topic to listen to
        topic:
      # set quality of service
        qos: 2
      # set cleanSession true = clean up session after client loses connection, false = keep data for client after connection loss (persistent session)
        cleanSession: true
      # set tupleBuffer flush interval in milliseconds
        flushIntervalMS: -1
      # Set input data format
        inputFormat: JSON
  # Set logical stream name where this stream is added to
  - logicalStreamName:
    # Set physical stream name
    physicalStreamName:
    # KafkaSource: Connect to a kafka broker and read data form there
    KafkaSourceType:
      # Set kafka broker string
      - brokers:
      # Set auto commit, boolean value where 1 equals true, and 0 equals false
        autoCommit: 1
      # Set groupId
        groupId:
      # Set topic to listen to
        topic: "test"
      # Set connection time out for source
        connectionTimeout: 10
  # Set logical stream name where this stream is added to
  - logicalStreamName:
    # Set physical stream name
    physicalStreamName:
    # OPCSource: connect to an OPC server and read data from there
    OPCSourceType:
    # Set namespaceIndex for node, needed for: OPCSource
      - namespaceIndex:
      # Set node identifier, needed for: OPCSource
        nodeIdentifier:
      # Set userName, needed for: MQTTSource (can be chosen arbitrary), OPCSource
        userName:
      # Set password, needed for: OPCSource
        password: