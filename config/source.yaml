# ~~~ Configurations for the Data Source ~~~

# ~~ Source Handling ~~
# Set the source type (available options: No_Source, DefaultSource, CSVSource, OPCSource, ZMQSource, KafkaSource, BinarySource, SenseSource)
sourceType: NoSource

# Set source configuration. Options depend on source type.
# DefaultSource: NoConfig (not needed)
# CSVSource: String with path to CSV file.
# MQTTSource: String set up as follows: "url;clientId;userId;topic;dataType;QoS;cleanSession"
#            url to connect to broker
#            clientId needed to connect to broker, system will add random number to it, to make sure it is unique per connection
#            userId string with user name
#            topic to connect to for data collection
#            dataType type of data we want to receive, currently only JSON implemented
#            qos Quality of Service (0 = at most once delivery, 1 = at leaste once delivery, 2 = exactly once delivery)
#            cleanSession true = clean up session after client loses connection, false = keep data for client after connection loss (persistent session)
# OPCSource (ToDo: Make source available): String set up as follows: "url;namespaceIndex;identifier;user;pwd"
#            where the url is a string containing the full OPC server url,
#            namespaceIndex is a uint16_t providing the namespanaceIndex for the nodeId,
#            identifier is a string containing the nodeId identifier,
#            user is a string containing the user name for server authentication ToDo: Implement server authentication.
#            pwd is a string containing the password for server authentication
# ZMQSource (ToDo: Make source available): String set up as: "host;port"
#            where host is a string containing the zmq host's ip address
#            and port is a uint16_t containing the zmq port
# KafkaSource (ToDo: Make source available): String set up as follows: "brokers;topic;groupId;autoCommit;kafkaConnectTimeout"
#            where brokers is a string containing the brokers's ip address,
#            topic is a string containing the topic,
#            groupId is a string containing the groupId,
#            autoCommit is a boolean value where 1 equals true, and 0 equals false,
#            kafkaConnectTimeout is a uint16_t providing the time out for the connection
# BinarySource: String with path to binary file.
# SenseSource (ToDo: Make source available): String with udsf inside
# YSBSource: NoConfig (not needed)
sourceConfig: NoConfig

# Set sampling frequency of source
sourceFrequency: 1

# Skip first line of the file
skipHeader: false

# Set number of buffers to produce
numberOfBuffersToProduce: 1

# Set number of tuples to produce per buffer
numberOfTuplesToProducePerBuffer: 0

# Set physical stream name
physicalStreamName: default_stream_phy

# Set logical stream name where this stream is added to
logicalStreamName: default_stream_log
